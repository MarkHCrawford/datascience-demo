{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction to Pandas"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas Basics\n",
        "\n",
        "Pandas is the most popular data analysis library for Python. It's inspired by earlier features of SQL and R, but has continued to progress and add support for the latest hardware technologies (parallel, in-memory, cloud, ...) as well as advanced analysis capabilities.\n",
        "\n",
        "The fundamental object we'll be using is the DataFrame. This is basically just a table, but with a lot of built-in, powerful data analysis methods."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataFrames and Series\n",
        "\n",
        "DataFrames are the table-like type used to store data in Pandas. Series are single columns of data - each column of a DataFrame is a series. You can make a series independently from a DataFrame, for example if you have a list and want to call some analysis methods on it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "groceries = {\"item\": [\"bananas\", \"apples\", \"oranges\"], \"quantity\": [4, 2, 8]}\n",
        "\n",
        "groceries_df = pd.DataFrame(groceries)\n",
        "\n",
        "print(\"Dict:\\n{}\\n\".format(groceries))\n",
        "print(\"DataFrame:\\n{}\".format(groceries_df))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = pd.Series([3.25, 4.50, 1.75])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can assign new columns to a DataFrame by writing:\n",
        "`df[\"new_column\"] = some_data`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "groceries_df[\"prices\"]= prices"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "df.head() prints the first 6 rows of the DataFrame"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "groceries_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing and Selecting Data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# select by column name\n",
        "print(groceries_df[\"item\"])\n",
        "# OR\n",
        "print(groceries_df.item)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "As a data scientist, you might know a lot about programming and statistics and have an area of specialty, but you often are asked to use your skills to solve a problem outside of your domain. One of the key skills you need to develop is the ability to explore a dataset so you can get more context about a particular domain. I'm guessing most of us don't know much about flowers or botany, so we're going to see what we can learn from the iris dataset!\n",
        "\n",
        "## Step 1: Describe the data at a high level"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset (built-in to scikit-learn)\n",
        "iris = load_iris()\n",
        "\n",
        "# create a DataFrame of the dataset\n",
        "ir = pd.DataFrame(iris.data)\n",
        "# set column names\n",
        "ir.columns = iris.feature_names\n",
        "# add species information\n",
        "ir['species'] = iris.target\n",
        "\n",
        "\n",
        "# look at the head of the dataset\n",
        "ir.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fix the column names! no spaces or characters!\n",
        "ir.columns = [x.replace(\" \", \"_\").replace(\"_(cm)\", \"\") for x in ir.columns]\n",
        "ir.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding/Decoding Data\n",
        "Sometimes you want to represent a categorical variable with an integer, like if you're building a model. Other times you might want to use a name, like if you're making a plot or analyzing a data frame. Let's convert the species codes to names!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# print the encoding scheme for species; 0 = Setosa , 1=Versicolor, 2= virginica\n",
        "print (iris.target_names)\n",
        "\n",
        "# write a small function to decode the names\n",
        "def iris_decoder(species_code):\n",
        "  if species_code == 0:\n",
        "    return \"Setosa\"\n",
        "  elif species_code == 1:\n",
        "    return \"Versicolor\"\n",
        "  else:\n",
        "    return \"Virginica\"\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the decoder using a lambda function (inline function) and assign to a new column\n",
        "ir['species_name'] = ir['species'].apply(lambda x: iris_decoder(x))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ir.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get summary statistics for each column in the dataset\n",
        "# note that there is no missing data!\n",
        "ir.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what types are the different variables?\n",
        "ir.dtypes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's _Object_? Let's look at the first data point and find out. Warning, object columns may have mixed types!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "type(ir.species_name[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Checking types\n",
        "Write some code that prints the type of each item in the *species_name* column. Hint: you can iterate over the items in a Pandas series..."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "species_name_types = []\n",
        "\n",
        "for item in ir.species_name:\n",
        "  species_name_types.append(str(type(item)))\n",
        " \n",
        "print(species_name_types)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Calculate some summary statistics and look at groups\n",
        "### Group By\n",
        "\n",
        "Group by will help you answer the vast majority of simple data analysis questions. The basic idea is that you group your data by the values of a variable or set of variables, then calculate a statistic of interest like the mean or minimum."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# mean of each feature for each group\n",
        "ir.groupby(\"species_name\").mean()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max of each feature for each group\n",
        "ir.groupby(\"species_name\").max()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how correlated are our variables? \n",
        "ir.corr()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization with Seaborn"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib\n",
        "# Initialize Figure and Axes object\n",
        "fig, ax = plt.subplots(figsize=(10,4))\n",
        "sns.set_context(\"notebook\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = ir.drop(\"species\", axis=1, inplace=False).corr()\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, cmap=cmap, vmax=1.0, center=0.0,\n",
        "            square=True, linewidths=.1,\n",
        "            cbar_kws={\"shrink\": .8})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.PairGrid(ir, hue=\"species_name\")\n",
        "g = g.map_diag(plt.hist, histtype=\"step\", linewidth=3)\n",
        "g = g.map_offdiag(plt.scatter)\n",
        "g = g.add_legend()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=ir, x=\"species_name\", y=\"sepal_length\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=ir, x=\"species_name\", y=\"sepal_width\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=\"sepal_length\", y=\"sepal_width\", hue=\"species_name\", data=ir)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=\"petal_length\", y=\"petal_width\", hue=\"species_name\", data=ir)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now that we have an idea of what the data looks like, let's try to build a model! The most important part of being a professional data scientist is to make sure your model is solving the right problem. Here we can imagine someone discovering a new flower and not knowing what species it is. We can build a model that can predict the species given the measurements of the flower!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_vars = ir[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
        "target = ir[\"species\"]\n",
        "\n",
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=500).fit(x_vars, target)\n",
        "\n",
        "# how did we do?\n",
        "print(clf.score(x_vars, target))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-means, #KNN"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what mistake did we make? overfitting!\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boston house prices dataset - Regression\n",
        "\n",
        "Regression models involve making a prediction for a continuous (or almost continuous) variable. Things like temperature, price, number of people watching the Super Bowl, etc... Let's look at the Boston house prices dataset to see if we can build a model to predict the price of a house, which could be useful to real estate agents, urban planners, economists, etc..."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston = load_boston()\n",
        "print(boston.DESCR)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create DataFrame and add target column\n",
        "boston_df = pd.DataFrame(boston.data)\n",
        "# set column names (do this before adding on the target)\n",
        "boston_df.columns = boston.feature_names\n",
        "# add target\n",
        "boston_df[\"MEDV\"] = boston.target\n",
        "boston_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick Check\n",
        "* What types are the variables?\n",
        "* Do we have any missing data?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.dtypes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA: Regression\n",
        "\n",
        "Since we don't have any defined groups in the data, we could make some, maybe using clustering, but for now let's focus on looking for correlations so we can build a good regression model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "boston_corr = boston_df.corr()\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(boston_corr, cmap=cmap, vmax=1.0, center=0.0,\n",
        "            square=True, linewidths=.1, cbar_kws={\"shrink\": .8})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston_corr.sort_values(by=[\"TAX\"], ascending=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#g = sns.PairGrid(boston_df)\n",
        "#g = g.map_diag(plt.hist, histtype=\"step\", linewidth=3)\n",
        "#g = g.map_offdiag(plt.scatter)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Time!\n",
        "\n",
        "We will be evaluating the regression models using Mean Squared Error = AVERAGE(Prediction - True)^2 and R^2 (explained variance).\n",
        "\n",
        "## Train/Test Split to avoid overfitting\n",
        "\n",
        "The biggest difference between descriptive statistics and predictive modeling is that the latter seeks to find a generalizable model that will be good at predicting unseen examples. So our goal isn't just to describe the data, it's to find a pattern that works on new/unseen examples.\n",
        "\n",
        "Overfitting is when your model finds patterns that are specific to your training data and fail to generalize on new examples. For instance, if I asked everyone in the room their favorite pizza topping, I could build a model that associates name to pizza topping. Like if your name is Sam and your favorite topping is pepperoni, I could build a model that says:\n",
        "\n",
        "`if name == \"Sam\":\n",
        "  return \"Pepperoni\"`\n",
        "\n",
        "But this wouldn't be a very good model.\n",
        "\n",
        "In order to combat overfitting, when we train a model we want to hold back some of our data for testing. This is called a train/test split. If our model performs well on the test data, then we can feel confident we didn't overfit.\n",
        "\n",
        "## IMPORTANT\n",
        "\n",
        "When you are training a model on time series data, it is VERY important to not use dates from the future in your training set. For example, if your dataset has data from 2010-2019, you would want to train on 2010-2017 and test on 2018-2019. There's no perfect rule for picking a data to split on, but whatever you do don't randomly sample the whole dataset!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "bos_x_train, bos_x_test, bos_y_train, bos_y_test = train_test_split(\n",
        "  boston_df.drop(\"MEDV\", axis=1, inplace=False),\n",
        "  boston_df[\"MEDV\"],\n",
        "  test_size=0.33,\n",
        "  random_state=42)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create linear regression object\n",
        "regr = LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(bos_x_train, bos_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "bos_y_pred = regr.predict(bos_x_test)\n",
        "\n",
        "# The coefficients\n",
        "print(\"COEFFICIENTS:\")\n",
        "for coef in zip(bos_x_train.columns, regr.coef_):\n",
        "    print(coef[0], \"{:.3f}\".format(coef[1]))\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: {:.2f}\".format(mean_squared_error(bos_y_test, bos_y_pred)))\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: {:.2f}'.format(r2_score(bos_y_test, bos_y_pred)))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "How do we know if this is a good mean squared error? Let's compare to a simple benchmark: the average of the training data prices:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "bos_y_train_mean = bos_y_train.mean()\n",
        "bos_mean_bench = pd.Series([bos_y_train_mean]).repeat(len(bos_y_test))\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: {:.2f}\".format(mean_squared_error(bos_y_test, bos_mean_bench)))\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: {:.2f}'.format(r2_score(bos_y_test, bos_mean_bench)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cool, so we beat the simplest possible model.\n",
        "\n",
        "Let's compare to a more sophisticated machine learning model:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_regr = RandomForestRegressor(\n",
        "  # We are minimizing MSE\n",
        "  criterion='mse',\n",
        "  # Bootstrap\n",
        "  bootstrap=True,\n",
        "  # How deep is each tree in the forest?\n",
        "  max_depth=4,\n",
        "  # How many trees are in the forest?\n",
        "  n_estimators=100,\n",
        "  # Set a random seed so we can reproduce the result\n",
        "  random_state=0,\n",
        "  # Do we want to print information to the console?\n",
        "  verbose=0 #2 YES\n",
        ")\n",
        "\n",
        "rf_regr.fit(bos_x_train, bos_y_train)  \n",
        "\n",
        "\n",
        "#criterion='mse', max_depth=2,\n",
        "#           max_features='auto', max_leaf_nodes=None,\n",
        "#           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "#           min_samples_leaf=1, min_samples_split=2,\n",
        "#           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
        "#           oob_score=False, random_state=0, verbose=0, warm_start=False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using the testing set\n",
        "bos_y_pred_rf = rf_regr.predict(bos_x_test)\n",
        "\n",
        "# The coefficients\n",
        "print(\"Feature Importances:\")\n",
        "for coef in zip(bos_x_train.columns, rf_regr.feature_importances_):\n",
        "    print(coef[0], \"{:.3f}\".format(coef[1]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The mean squared error\n",
        "print(\"Mean squared error: {:.2f}\".format(mean_squared_error(bos_y_test, bos_y_pred_rf)))\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: {:.2f}'.format(r2_score(bos_y_test, bos_y_pred_rf)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the models!"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling Skills\n",
        "\n",
        "## How to read data from a file"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# this works for a small file :)\n",
        "with open(\"example_dataset.csv\") as f:\n",
        "  for line in f:\n",
        "    print(line)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this works for a big file (read first N lines)\n",
        "N = 3\n",
        "with open(\"example_dataset.csv\") as f:\n",
        "    head = [next(f) for x in range(N)]\n",
        "\n",
        "for line in head:\n",
        "  print(line)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use read_csv for csv files. There is also read_excel for Excel files.\n",
        "example_df = pd.read_csv(\"example_dataset.csv\", sep=\",\")\n",
        "example_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to handle missing data\n",
        "\n",
        "First, see how much data you are missing and where it's missing from!\n",
        "\n",
        "Then, you can do any/all/none of the following:\n",
        "1. Drop the missing data\n",
        "2. Impute the missing data\n",
        "3. Predict the missing data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "example_df.dropna()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute the mean for each group\n",
        "team_mean_hits = (example_df[[\"team\", \"hits\"]]\n",
        "                  .groupby(\"team\")\n",
        "                  .mean()\n",
        "                  .reset_index())\n",
        "\n",
        "team_mean_hits.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select the missing rows\n",
        "example_df.loc[pd.isna(example_df.hits)]\n",
        "#example_df.hits.loc[pd.isna(example_df.hits)]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge the team mean hits (outer = keep all rows)\n",
        "baseball_merged = example_df.merge(team_mean_hits, on=\"team\", how=\"outer\", suffixes=(\"\", \"_mean\"))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseball_merged[\"hits_imp\"] = baseball_merged.hits.combine_first(baseball_merged.hits_mean)\n",
        "baseball_merged.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remember where we imputed (this only works BEFORE you impute the missing data!)\n",
        "example_df[\"hits_missing\"] = pd.isna(example_df.hits)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}